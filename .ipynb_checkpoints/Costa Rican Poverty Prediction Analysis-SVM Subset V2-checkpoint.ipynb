{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Costa Rican Poverty Predction </h1> </center>\n",
    "<center> <h2> by: Jason Lin, Jason Lingle, and Jonathan Marin </h2> </center>\n",
    "<center> <h2> 10/7/2018 </h2> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pandasql import sqldf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "\n",
    "train = pd.DataFrame(pd.read_csv(\"train.csv\"))\n",
    "test = pd.DataFrame(pd.read_csv(\"test.csv\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v2a1       6860\n",
       "v18q1      7342\n",
       "rez_esc    7928\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Find the Nulls\n",
    "null_columns=train.columns[train.isnull().any()]\n",
    "\n",
    "train[null_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v2a1        949\n",
       "rez_esc    7928\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update and Check to see we updated\n",
    "\n",
    "# There are 2156 null values for v2a1 (monthly mortgage payment).  After accounting for those that don't \n",
    "#rent, we are left with 300 values that have nulls.  We can try to create a model \n",
    "\n",
    "train.loc[(train.tipovivi1 == 1),'v2a1'] = 0\n",
    "test.loc[(test.tipovivi1 == 1),'v2a1'] = 0\n",
    "\n",
    "\n",
    "train.loc[np.isnan(train[\"v18q1\"]), 'v18q1'] = 0\n",
    "test.loc[np.isnan(test[\"v18q1\"]), 'v18q1'] = 0\n",
    "\n",
    "train.loc[np.isnan(train[\"v18q1\"]), 'v18q1'] = 0\n",
    "test.loc[np.isnan(test[\"v18q1\"]), 'v18q1'] = 0\n",
    "\n",
    "\n",
    "train.loc[(train.dependency == \"yes\"),'dependency'] = 1\n",
    "train.loc[(train.dependency == \"no\"),'dependency'] = 0\n",
    "\n",
    "test.loc[(test.dependency == \"yes\"),'dependency'] = 1\n",
    "test.loc[(test.dependency == \"no\"),'dependency'] = 0\n",
    "\n",
    "\n",
    "train.loc[(train.edjefe == \"yes\"),'edjefe'] = 1\n",
    "train.loc[(train.edjefe == \"no\"),'edjefe'] = 0\n",
    "\n",
    "test.loc[(test.edjefe == \"yes\"),'edjefe'] = 1\n",
    "test.loc[(test.edjefe == \"no\"),'edjefe'] = 0\n",
    "\n",
    "\n",
    "\n",
    "train.loc[(train.edjefa == \"yes\"),'edjefa'] = 1\n",
    "train.loc[(train.edjefa == \"no\"),'edjefa'] = 0\n",
    "\n",
    "test.loc[(test.edjefa == \"yes\"),'edjefa'] = 1\n",
    "test.loc[(test.edjefa == \"no\"),'edjefa'] = 0\n",
    "\n",
    "\n",
    "null_columns=train.columns[train.isnull().any()]\n",
    "\n",
    "train[null_columns].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Denormalization\n",
    "\n",
    "#Create subset dataframes for head of househoold for tain and test\n",
    "train_head = train[['idhogar', 'parentesco1', 'Id', 'hhsize', 'v2a1', 'hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'v18q1', 'r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3', 'tamhog', 'tamviv', 'paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera', 'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', 'abastaguadentro', 'abastaguafuera', 'abastaguano', 'public', 'planpri', 'noelec', 'coopele', 'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6', 'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', 'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total', 'dependency', 'edjefe', 'edjefa', 'meaneduc', 'bedrooms', 'overcrowding', 'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', 'computer', 'television', 'qmobilephone', 'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6', 'area1', 'area2', 'SQBescolari', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned','Target']]\n",
    "\n",
    "train_head = train_head[train_head['parentesco1'] == 1]\n",
    "\n",
    "test_head = test[['idhogar', 'parentesco1', 'Id', 'hhsize', 'v2a1', 'hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'v18q1', 'r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3', 'tamhog', 'tamviv', 'paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera', 'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', 'abastaguadentro', 'abastaguafuera', 'abastaguano', 'public', 'planpri', 'noelec', 'coopele', 'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6', 'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', 'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total', 'dependency', 'edjefe', 'edjefa', 'meaneduc', 'bedrooms', 'overcrowding', 'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', 'computer', 'television', 'qmobilephone', 'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6', 'area1', 'area2', 'SQBescolari', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned']]\n",
    "\n",
    "test_head = test_head[test_head['parentesco1'] == 1]\n",
    "\n",
    "#Start the member level denormalization for train and test\n",
    "train_member_agg = pd.DataFrame(sqldf(\"select  \"\n",
    "\"idhogar, \"\n",
    "\"sum(cast(v18q as int)) 'JM_Sum_of_Tablets', \"\n",
    "\"sum(cast(escolari as int)) 'Total Sum Years of Schooling', \"\n",
    "\"sum(case when escolari < 5 then 1 else 0 end) as 'JM_People_Educ_LT5', \"\n",
    "\"sum(case when escolari < 10 then 1 else 0 end) as 'JM_People_Educ_LT10', \"\n",
    "\"sum(case when escolari < 15 then 1 else 0 end) as 'JM_People_Educ_LT15', \"\n",
    "\"sum(case when escolari < 20 then 1 else 0 end) as 'JM_People_Educ_LT20', \"\n",
    "\"sum(case when escolari < 25 then 1 else 0 end) as 'JM_People_Educ_LT25', \"\n",
    "\"sum(case when rez_esc = 1 then 1 else 0 end) as 'JM_1YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 2 then 1 else 0 end) as 'JM_2YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 3 then 1 else 0 end) as 'JM_3YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 4 then 1 else 0 end) as 'JM_4YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 5 then 1 else 0 end) as 'JM_5YrBehindSchool', \"\n",
    "\"sum(cast(dis as int)) as 'JM_Sum_of_Disabled', \"\n",
    "\"sum(cast(male as int)) as 'JM_Sum_Of_Males', \"\n",
    "\"sum(cast(female as int)) as 'JM_Sum_Of_Females', \"\n",
    "\"sum(cast(estadocivil1 as int)) as  'JM_estadocivil1', \"\n",
    "\"sum(cast(estadocivil2 as int)) as  'JM_estadocivil2', \"\n",
    "\"sum(cast(estadocivil3 as int)) as  'JM_estadocivil3', \"\n",
    "\"sum(cast(estadocivil4 as int)) as  'JM_estadocivil4', \"\n",
    "\"sum(cast(estadocivil5 as int)) as  'JM_estadocivil5', \"\n",
    "\"sum(cast(estadocivil6 as int)) as  'JM_estadocivil6', \"\n",
    "\"sum(cast(estadocivil7 as int)) as  'JM_estadocivil7', \"\n",
    "\"sum(cast(parentesco1 as int)) as  'JM_parentesco1', \"\n",
    "\"sum(cast(parentesco2 as int)) as  'JM_parentesco2', \"\n",
    "\"sum(cast(parentesco3 as int)) as  'JM_parentesco3', \"\n",
    "\"sum(cast(parentesco4 as int)) as  'JM_parentesco4', \"\n",
    "\"sum(cast(parentesco5 as int)) as  'JM_parentesco5', \"\n",
    "\"sum(cast(parentesco6 as int)) as  'JM_parentesco6', \"\n",
    "\"sum(cast(parentesco7 as int)) as  'JM_parentesco7', \"\n",
    "\"sum(cast(parentesco8 as int)) as  'JM_parentesco8', \"\n",
    "\"sum(cast(parentesco9 as int)) as  'JM_parentesco9', \"\n",
    "\"sum(cast(parentesco10 as int)) as  'JM_parentesco10', \"\n",
    "\"sum(cast(parentesco11 as int)) as  'JM_parentesco11', \"\n",
    "\"sum(cast(parentesco12 as int)) as  'JM_parentesco12', \"\n",
    "\"sum(cast(instlevel1 as int)) as  'JM_instlevel1', \"\n",
    "\"sum(cast(instlevel2 as int)) as  'JM_instlevel2', \"\n",
    "\"sum(cast(instlevel3 as int)) as  'JM_instlevel3', \"\n",
    "\"sum(cast(instlevel4 as int)) as  'JM_instlevel4', \"\n",
    "\"sum(cast(instlevel5 as int)) as  'JM_instlevel5', \"\n",
    "\"sum(cast(instlevel6 as int)) as  'JM_instlevel6', \"\n",
    "\"sum(cast(instlevel7 as int)) as  'JM_instlevel7', \"\n",
    "\"sum(cast(instlevel8 as int)) as  'JM_instlevel8', \"\n",
    "\"sum(cast(instlevel9 as int)) as  'JM_instlevel9', \"\n",
    "\"sum(cast(mobilephone as int)) as  'JM_mobilephone'\" \n",
    "\"from train \"\n",
    "\"group by idhogar \"\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "test_member_agg = pd.DataFrame(sqldf(\"select  \"\n",
    "\"idhogar, \"\n",
    "\"sum(cast(v18q as int)) 'JM_Sum_of_Tablets', \"\n",
    "\"sum(cast(escolari as int)) 'Total Sum Years of Schooling', \"\n",
    "\"sum(case when escolari < 5 then 1 else 0 end) as 'JM_People_Educ_LT5', \"\n",
    "\"sum(case when escolari < 10 then 1 else 0 end) as 'JM_People_Educ_LT10', \"\n",
    "\"sum(case when escolari < 15 then 1 else 0 end) as 'JM_People_Educ_LT15', \"\n",
    "\"sum(case when escolari < 20 then 1 else 0 end) as 'JM_People_Educ_LT20', \"\n",
    "\"sum(case when escolari < 25 then 1 else 0 end) as 'JM_People_Educ_LT25', \"\n",
    "\"sum(case when rez_esc = 1 then 1 else 0 end) as 'JM_1YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 2 then 1 else 0 end) as 'JM_2YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 3 then 1 else 0 end) as 'JM_3YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 4 then 1 else 0 end) as 'JM_4YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 5 then 1 else 0 end) as 'JM_5YrBehindSchool', \"\n",
    "\"sum(cast(dis as int)) as 'JM_Sum_of_Disabled', \"\n",
    "\"sum(cast(male as int)) as 'JM_Sum_Of_Males', \"\n",
    "\"sum(cast(female as int)) as 'JM_Sum_Of_Females', \"\n",
    "\"sum(cast(estadocivil1 as int)) as  'JM_estadocivil1', \"\n",
    "\"sum(cast(estadocivil2 as int)) as  'JM_estadocivil2', \"\n",
    "\"sum(cast(estadocivil3 as int)) as  'JM_estadocivil3', \"\n",
    "\"sum(cast(estadocivil4 as int)) as  'JM_estadocivil4', \"\n",
    "\"sum(cast(estadocivil5 as int)) as  'JM_estadocivil5', \"\n",
    "\"sum(cast(estadocivil6 as int)) as  'JM_estadocivil6', \"\n",
    "\"sum(cast(estadocivil7 as int)) as  'JM_estadocivil7', \"\n",
    "\"sum(cast(parentesco1 as int)) as  'JM_parentesco1', \"\n",
    "\"sum(cast(parentesco2 as int)) as  'JM_parentesco2', \"\n",
    "\"sum(cast(parentesco3 as int)) as  'JM_parentesco3', \"\n",
    "\"sum(cast(parentesco4 as int)) as  'JM_parentesco4', \"\n",
    "\"sum(cast(parentesco5 as int)) as  'JM_parentesco5', \"\n",
    "\"sum(cast(parentesco6 as int)) as  'JM_parentesco6', \"\n",
    "\"sum(cast(parentesco7 as int)) as  'JM_parentesco7', \"\n",
    "\"sum(cast(parentesco8 as int)) as  'JM_parentesco8', \"\n",
    "\"sum(cast(parentesco9 as int)) as  'JM_parentesco9', \"\n",
    "\"sum(cast(parentesco10 as int)) as  'JM_parentesco10', \"\n",
    "\"sum(cast(parentesco11 as int)) as  'JM_parentesco11', \"\n",
    "\"sum(cast(parentesco12 as int)) as  'JM_parentesco12', \"\n",
    "\"sum(cast(instlevel1 as int)) as  'JM_instlevel1', \"\n",
    "\"sum(cast(instlevel2 as int)) as  'JM_instlevel2', \"\n",
    "\"sum(cast(instlevel3 as int)) as  'JM_instlevel3', \"\n",
    "\"sum(cast(instlevel4 as int)) as  'JM_instlevel4', \"\n",
    "\"sum(cast(instlevel5 as int)) as  'JM_instlevel5', \"\n",
    "\"sum(cast(instlevel6 as int)) as  'JM_instlevel6', \"\n",
    "\"sum(cast(instlevel7 as int)) as  'JM_instlevel7', \"\n",
    "\"sum(cast(instlevel8 as int)) as  'JM_instlevel8', \"\n",
    "\"sum(cast(instlevel9 as int)) as  'JM_instlevel9', \"\n",
    "\"sum(cast(mobilephone as int)) as  'JM_mobilephone'\" \n",
    "\"from test \"\n",
    "\"group by idhogar \"\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "#Join the household and member aggregation together\n",
    "train_model_set = pd.DataFrame(pd.merge(train_head, train_member_agg, on = 'idhogar', how = 'left'))\n",
    "test_model_set = pd.DataFrame(pd.merge(test_head, test_member_agg, on = 'idhogar', how = 'left'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For the rest of the v2a1 that are null, we will use the mean\n",
    "\n",
    "train_model_set['v2a1'].fillna((train_model_set['v2a1'].mean()), inplace=True)\n",
    "\n",
    "test_model_set['v2a1'].fillna((train_model_set['v2a1'].mean()), inplace=True)\n",
    "\n",
    "#Export final model csvs for review\n",
    "train_model_set.to_csv(\"train_model_set.csv\")\n",
    "test_model_set.to_csv(\"test_model_set.csv\")\n",
    "\n",
    "#Make sure all Nulls are accounted for\n",
    "null_columns=train_model_set.columns[train_model_set.isnull().any()]\n",
    "\n",
    "train_model_set[null_columns].isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the Keys\n",
    "train_model_set = train_model_set.drop('Id', axis = 1)\n",
    "train_model_set = train_model_set.drop('idhogar', axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain Dependent and Independent Variables\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = train_model_set.drop('Target', axis = 1)\n",
    "y = train_model_set.Target\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train and test set from train\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.694117647059\n",
      "confusion matrix\n",
      " [[  9  17   0  17]\n",
      " [  8  24   6  53]\n",
      " [  4   6   7  60]\n",
      " [  3   6   2 373]]\n"
     ]
    }
   ],
   "source": [
    "#Running Logistic Regression\n",
    "\n",
    "# run logistic regression and vary some parameters\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "\n",
    "lr_clf = LogisticRegression(C=1,  class_weight=None)\n",
    "  \n",
    "# train the reusable logisitc regression model on the training data\n",
    "X_train2 = X_train.drop(['r4m3','r4t3','r4h3','v2a1','refrig','JM_Sum_of_Tablets','r4h1','r4h2','r4m2','r4t2','r4t3','tamhog','paredpreb','pareddes','paredfibras','paredother','pisomoscer','pisocemento',\n",
    "                        'pisoother','pisonatur','techozinc','techoentrepiso','techootro','abastaguano','noelec','sanitario1','sanitario3','sanitario6','energcocinar2','elimbasu1','elimbasu2','elimbasu4','elimbasu5',\n",
    "                         'epared1','etecho2','eviv1','hogar_nin','computer','parentesco1','JM_parentesco1'],axis=1)\n",
    "X_test2= X_test.drop(['r4m3','r4t3','r4h3','v2a1','refrig','JM_Sum_of_Tablets','r4h1','r4h2','r4m2','r4t2','r4t3','tamhog','paredpreb','pareddes','paredfibras','paredother','pisomoscer','pisocemento',\n",
    "                     'pisoother','pisonatur','techozinc','techoentrepiso','techootro','abastaguano','noelec','sanitario1','sanitario3','sanitario6','energcocinar2','elimbasu1','elimbasu2','elimbasu4','elimbasu5'\n",
    "                     ,'epared1','etecho2','eviv1','hogar_nin','computer','parentesco1','JM_parentesco1'],axis=1)\n",
    "lr_clf.fit(X_train2,y_train)  # train object\n",
    "y_hat = lr_clf.predict(X_test2) # get test set precitions\n",
    "\n",
    "# now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "\n",
    "print(\"accuracy\", acc )\n",
    "print(\"confusion matrix\\n\",conf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for Logistic Regression is .69.  When looking at the confusion matrix, we seem to be predicting the wealthiest people more accurately/heavily than the poverty classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost 0.001 Accuracy 0.667226890756\n",
      "Cost 0.01 Accuracy 0.685714285714\n",
      "Cost 0.05 Accuracy 0.690756302521\n",
      "Cost 0.1 Accuracy 0.695798319328\n",
      "Cost 0.5 Accuracy 0.695798319328\n",
      "Cost 1 Accuracy 0.694117647059\n",
      "Cost 5 Accuracy 0.689075630252\n",
      "Cost 10 Accuracy 0.689075630252\n",
      "Cost 30 Accuracy 0.687394957983\n",
      "Cost 50 Accuracy 0.690756302521\n",
      "Cost 90 Accuracy 0.690756302521\n",
      "Cost 100 Accuracy 0.685714285714\n",
      "Cost 500 Accuracy 0.690756302521\n",
      "Cost 1000 Accuracy 0.685714285714\n",
      "Cost 1500 Accuracy 0.685714285714\n"
     ]
    }
   ],
   "source": [
    "#Adjusting Cost to see change in Accuracy for logistic\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "cost =[0.001,0.01,0.05,0.1,0.5,1,5,10,30,50,90,100,500,1000,1500]\n",
    "for i in cost:\n",
    "    lr_clf = LogisticRegression(C=i,  class_weight=None)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "  \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    X_train2 = X_train.drop(['r4m3','r4t3','r4h3','v2a1','refrig','JM_Sum_of_Tablets','r4h1','r4h2','r4m2','r4t2','r4t3','tamhog','paredpreb','pareddes','paredfibras','paredother','pisomoscer','pisocemento',\n",
    "                            'pisoother','pisonatur','techozinc','techoentrepiso','techootro','abastaguano','noelec','sanitario1','sanitario3','sanitario6','energcocinar2','elimbasu1','elimbasu2','elimbasu4','elimbasu5',\n",
    "                             'epared1','etecho2','eviv1','hogar_nin','computer','parentesco1','JM_parentesco1'],axis=1)\n",
    "    X_test2= X_test.drop(['r4m3','r4t3','r4h3','v2a1','refrig','JM_Sum_of_Tablets','r4h1','r4h2','r4m2','r4t2','r4t3','tamhog','paredpreb','pareddes','paredfibras','paredother','pisomoscer','pisocemento',\n",
    "                         'pisoother','pisonatur','techozinc','techoentrepiso','techootro','abastaguano','noelec','sanitario1','sanitario3','sanitario6','energcocinar2','elimbasu1','elimbasu2','elimbasu4','elimbasu5'\n",
    "                         ,'epared1','etecho2','eviv1','hogar_nin','computer','parentesco1','JM_parentesco1'],axis=1)\n",
    "    lr_clf.fit(X_train2,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test2) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print('Cost',i,'Accuracy',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running through different cost parameters we see that the cost of .1/.5 has the best accuracy and there seems to be a relationship where each cost after .1/.5 gets worse and all values before get worse as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.598319327731\n",
      "confusion matrix\n",
      " [[  1   8   1  33]\n",
      " [  7  14  10  60]\n",
      " [  3   8   4  62]\n",
      " [ 11  21  15 337]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#SVM Model\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scl_obj = StandardScaler()\n",
    "#X_train_sv = X_train[['meaneduc','JM_People_Educ_LT15','overcrowding','public']]\n",
    "#X_test_sv = X_test[['meaneduc','JM_People_Educ_LT15','overcrowding','public']]\n",
    "#scl_obj.fit(X_train_sv)\n",
    "\n",
    "#X_train_scaled = scl_obj.transform(X_train_sv)\n",
    "#X_test_scaled = scl_obj.transform(X_test_sv) \n",
    "svm_clf = svm.SVC(gamma='auto', C=100, kernel='rbf')\n",
    "svm_clf.fit(X_train, y_train)  \n",
    "\n",
    "y_hat2 = svm_clf.predict(X_test)\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat2)\n",
    "conf = mt.confusion_matrix(y_test,y_hat2)\n",
    "\n",
    "print(\"accuracy\", acc )\n",
    "print(\"confusion matrix\\n\",conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the SVM model, the accuracy is .59.  When looking at the confusion matrix, we seem to be predicting the wealthiest people more accurately/heavily than the poverty classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost 0.001 accuracy 0.645378151261\n",
      "Cost 0.01 accuracy 0.645378151261\n",
      "Cost 0.05 accuracy 0.645378151261\n",
      "Cost 0.1 accuracy 0.645378151261\n",
      "Cost 0.5 accuracy 0.647058823529\n",
      "Cost 1 accuracy 0.633613445378\n",
      "Cost 5 accuracy 0.610084033613\n",
      "Cost 10 accuracy 0.606722689076\n",
      "Cost 30 accuracy 0.598319327731\n",
      "Cost 50 accuracy 0.598319327731\n",
      "Cost 90 accuracy 0.598319327731\n",
      "Cost 100 accuracy 0.598319327731\n",
      "Cost 500 accuracy 0.598319327731\n",
      "Cost 1000 accuracy 0.598319327731\n",
      "Cost 1500 accuracy 0.598319327731\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "cost_sv =[0.001,0.01,0.05,0.1,0.5,1,5,10,30,50,90,100,500,1000,1500]\n",
    "for j in cost_sv:\n",
    "    svm_clf = svm.SVC(gamma='auto', C=j, kernel='rbf')\n",
    "    svm_clf.fit(X_train, y_train)  \n",
    "\n",
    "    y_hat2 = svm_clf.predict(X_test)\n",
    "\n",
    "    acc = mt.accuracy_score(y_test,y_hat2)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat2)\n",
    "\n",
    "    print(\"Cost\",j,\"accuracy\", acc )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running through different cost parameters we see that the cost of .5 has the best accuracy and there seems to be a relationship where each cost after .5 gets worse and all values before get worse as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma 0.001 accuracy 0.58487394958\n",
      "Gamma 0.01 accuracy 0.598319327731\n",
      "Gamma 0.05 accuracy 0.631932773109\n",
      "Gamma 0.1 accuracy 0.645378151261\n",
      "Gamma 0.5 accuracy 0.645378151261\n",
      "Gamma 1 accuracy 0.645378151261\n",
      "Gamma 5 accuracy 0.645378151261\n",
      "Gamma 10 accuracy 0.645378151261\n",
      "Gamma 30 accuracy 0.645378151261\n",
      "Gamma 50 accuracy 0.645378151261\n",
      "Gamma 90 accuracy 0.645378151261\n",
      "Gamma 100 accuracy 0.645378151261\n",
      "Gamma 500 accuracy 0.645378151261\n",
      "Gamma 1000 accuracy 0.645378151261\n",
      "Gamma 1500 accuracy 0.645378151261\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "gamma_sv =[0.001,0.01,0.05,0.1,0.5,1,5,10,30,50,90,100,500,1000,1500]\n",
    "for k in gamma_sv:\n",
    "    svm_clf = svm.SVC(gamma=k, C=100, kernel='rbf')\n",
    "    svm_clf.fit(X_train, y_train)  \n",
    "\n",
    "    y_hat2 = svm_clf.predict(X_test)\n",
    "\n",
    "    acc = mt.accuracy_score(y_test,y_hat2)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat2)\n",
    "\n",
    "    print(\"Gamma\",k,\"accuracy\", acc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "After a gamma of .1, the accuracy is the best and seems to be the same for all gamma values above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.690756302521\n",
      "confusion matrix\n",
      " [[  7  13   1  22]\n",
      " [  5  28   5  53]\n",
      " [  1   9   7  60]\n",
      " [  1   9   5 369]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_hat3 = rf_clf.predict(X_test)\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat3)\n",
    "conf = mt.confusion_matrix(y_test,y_hat3)\n",
    "\n",
    "print(\"accuracy\", acc )\n",
    "print(\"confusion matrix\\n\",conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran the Random Forest classifcation model out of curiousity because of how well it performs over others usually and we see that it actually does better in classifying the poverty class better than all previous models and the accuracy is .69. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Advantages\n",
    "\n",
    "Logistic Regression seems to be higher in accuracy and have better performance than SVM especially when using the linear kernal as that took a long time to process because SVM would treat every variable as an independent vector. We also ran Random Forest just as a benchmark and Random Forest seemed to be the best model in regards to accuracy.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Feature Importance\n",
    "\n",
    "Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. Why do you think some variables are more important?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.694117647059\n",
      "[[ 10  16   0  17]\n",
      " [  8  26   5  52]\n",
      " [  5   6   7  59]\n",
      " [  4   7   3 370]]\n",
      "model 1 variable SQBovercrowding has weight of -0.516961600057\n",
      "model 1 variable qmobilephone has weight of -0.51021643553\n",
      "model 1 variable meaneduc has weight of -0.50259009367\n",
      "model 1 variable hogar_adul has weight of -0.461344682039\n",
      "model 1 variable SQBescolari has weight of -0.360123154267\n",
      "model 1 variable hhsize has weight of -0.359647072574\n",
      "model 1 variable hogar_total has weight of -0.359647072574\n",
      "model 1 variable Total Sum Years of Schooling has weight of -0.347020871563\n",
      "model 1 variable dependency has weight of -0.345958680383\n",
      "model 1 variable JM_instlevel9 has weight of -0.275837076378\n",
      "model 1 variable JM_parentesco4 has weight of -0.24718943675\n",
      "model 1 variable JM_estadocivil6 has weight of -0.210927342184\n",
      "model 1 variable tipovivi3 has weight of -0.163208457232\n",
      "model 1 variable JM_parentesco6 has weight of -0.16230468719\n",
      "model 1 variable cielorazo has weight of -0.159727959941\n",
      "model 1 variable r4m1 has weight of -0.158517774447\n",
      "model 1 variable edjefe has weight of -0.148741460385\n",
      "model 1 variable JM_Sum_Of_Males has weight of -0.139163666343\n",
      "model 1 variable sanitario2 has weight of -0.134497450513\n",
      "model 1 variable JM_People_Educ_LT10 has weight of -0.134268799485\n",
      "model 1 variable elimbasu6 has weight of -0.126569519069\n",
      "model 1 variable JM_instlevel6 has weight of -0.114417594018\n",
      "model 1 variable television has weight of -0.113944882645\n",
      "model 1 variable JM_estadocivil2 has weight of -0.106115641865\n",
      "model 1 variable paredblolad has weight of -0.100879482544\n",
      "model 1 variable JM_parentesco9 has weight of -0.0914810923604\n",
      "model 1 variable lugar5 has weight of -0.0876796796624\n",
      "model 1 variable eviv3 has weight of -0.0838758144406\n",
      "model 1 variable JM_instlevel8 has weight of -0.0835471289066\n",
      "model 1 variable pisonotiene has weight of -0.071494046335\n",
      "model 1 variable JM_mobilephone has weight of -0.0654308147611\n",
      "model 1 variable lugar1 has weight of -0.0635559634534\n",
      "model 1 variable JM_parentesco12 has weight of -0.0524991609444\n",
      "model 1 variable area2 has weight of -0.0503224478639\n",
      "model 1 variable hacapo has weight of -0.0448927601634\n",
      "model 1 variable etecho3 has weight of -0.04410519294\n",
      "model 1 variable planpri has weight of -0.0433428517221\n",
      "model 1 variable tipovivi2 has weight of -0.0396752516669\n",
      "model 1 variable JM_3YrBehindSchool has weight of -0.0373272108094\n",
      "model 1 variable JM_1YrBehindSchool has weight of -0.0371426592445\n",
      "model 1 variable v14a has weight of -0.0294928396921\n",
      "model 1 variable JM_parentesco10 has weight of -0.0257126735723\n",
      "model 1 variable hogar_mayor has weight of -0.0200724274272\n",
      "model 1 variable lugar6 has weight of -0.0114832618866\n",
      "model 1 variable paredzocalo has weight of -0.00991266518825\n",
      "model 1 variable energcocinar3 has weight of -0.00425771344082\n",
      "model 1 variable sanitario5 has weight of -0.00413783181233\n",
      "model 1 variable JM_instlevel3 has weight of -0.00360120701478\n",
      "model 1 variable v18q1 has weight of -0.00334941877816\n",
      "model 1 variable JM_estadocivil4 has weight of -0.0019800608086\n",
      "model 1 variable pisomadera has weight of -0.000713242549928\n",
      "model 1 variable paredzinc has weight of 0.00106691655008\n",
      "model 1 variable SQBhogar_total has weight of 0.00361231450956\n",
      "model 1 variable elimbasu3 has weight of 0.00586420390972\n",
      "model 1 variable JM_Sum_of_Disabled has weight of 0.00607959889082\n",
      "model 1 variable tipovivi5 has weight of 0.00637376455457\n",
      "model 1 variable JM_People_Educ_LT5 has weight of 0.00746488587532\n",
      "model 1 variable epared3 has weight of 0.0106251441159\n",
      "model 1 variable JM_parentesco8 has weight of 0.0128860925805\n",
      "model 1 variable JM_estadocivil3 has weight of 0.0135156348268\n",
      "model 1 variable JM_parentesco7 has weight of 0.0145164663082\n",
      "model 1 variable energcocinar4 has weight of 0.0301199165675\n",
      "model 1 variable tipovivi4 has weight of 0.0352305247522\n",
      "model 1 variable JM_People_Educ_LT20 has weight of 0.0397829911145\n",
      "model 1 variable JM_People_Educ_LT25 has weight of 0.0418200735399\n",
      "model 1 variable lugar2 has weight of 0.0444268221989\n",
      "model 1 variable SQBdependency has weight of 0.0455046796403\n",
      "model 1 variable epared2 has weight of 0.0460971805937\n",
      "model 1 variable eviv2 has weight of 0.047015187403\n",
      "model 1 variable area1 has weight of 0.0503224478639\n",
      "model 1 variable techocane has weight of 0.0536958726037\n",
      "model 1 variable bedrooms has weight of 0.0538385467842\n",
      "model 1 variable JM_estadocivil1 has weight of 0.0547006800326\n",
      "model 1 variable paredmad has weight of 0.0598590417596\n",
      "model 1 variable JM_5YrBehindSchool has weight of 0.0600541432146\n",
      "model 1 variable lugar3 has weight of 0.064545535651\n",
      "model 1 variable JM_parentesco5 has weight of 0.0695688858016\n",
      "model 1 variable SQBhogar_nin has weight of 0.0895873468508\n",
      "model 1 variable JM_2YrBehindSchool has weight of 0.0899167560965\n",
      "model 1 variable JM_4YrBehindSchool has weight of 0.0901521380673\n",
      "model 1 variable JM_estadocivil7 has weight of 0.0912093130869\n",
      "model 1 variable JM_instlevel7 has weight of 0.0978882251828\n",
      "model 1 variable energcocinar1 has weight of 0.11296929003\n",
      "model 1 variable lugar4 has weight of 0.113411509101\n",
      "model 1 variable JM_parentesco3 has weight of 0.113655086568\n",
      "model 1 variable JM_instlevel4 has weight of 0.125508449854\n",
      "model 1 variable tamviv has weight of 0.133343797051\n",
      "model 1 variable JM_parentesco2 has weight of 0.135265093744\n",
      "model 1 variable etecho1 has weight of 0.138442592128\n",
      "model 1 variable tipovivi1 has weight of 0.141247957342\n",
      "model 1 variable JM_estadocivil5 has weight of 0.141523161523\n",
      "model 1 variable SQBedjefe has weight of 0.181030618583\n",
      "model 1 variable hacdor has weight of 0.184224389363\n",
      "model 1 variable JM_instlevel5 has weight of 0.185550848913\n",
      "model 1 variable JM_instlevel1 has weight of 0.197871028513\n",
      "model 1 variable JM_Sum_Of_Females has weight of 0.197988736877\n",
      "model 1 variable JM_parentesco11 has weight of 0.208706638004\n",
      "model 1 variable rooms has weight of 0.222013448288\n",
      "model 1 variable JM_instlevel2 has weight of 0.223220780574\n",
      "model 1 variable edjefa has weight of 0.244988118183\n",
      "model 1 variable r4t1 has weight of 0.261343906553\n",
      "model 1 variable SQBmeaned has weight of 0.284111895858\n",
      "model 1 variable abastaguafuera has weight of 0.473334710427\n",
      "model 1 variable abastaguadentro has weight of 0.48899681512\n",
      "model 1 variable coopele has weight of 0.556288807804\n",
      "model 1 variable overcrowding has weight of 0.570581988204\n",
      "model 1 variable public has weight of 0.591548768943\n",
      "model 1 variable JM_People_Educ_LT15 has weight of 0.674229260011\n",
      "model 2 variable hogar_adul has weight of -0.827561163955\n",
      "model 2 variable SQBedjefe has weight of -0.408313495464\n",
      "model 2 variable JM_instlevel9 has weight of -0.392202136122\n",
      "model 2 variable SQBescolari has weight of -0.363237542355\n",
      "model 2 variable hacdor has weight of -0.314071630456\n",
      "model 2 variable hhsize has weight of -0.304348514167\n",
      "model 2 variable hogar_total has weight of -0.304348514167\n",
      "model 2 variable eviv3 has weight of -0.283433053236\n",
      "model 2 variable techocane has weight of -0.272316080714\n",
      "model 2 variable overcrowding has weight of -0.262519301616\n",
      "model 2 variable SQBhogar_total has weight of -0.234648006564\n",
      "model 2 variable v18q1 has weight of -0.220310208079\n",
      "model 2 variable rooms has weight of -0.212246123078\n",
      "model 2 variable JM_5YrBehindSchool has weight of -0.202821548938\n",
      "model 2 variable qmobilephone has weight of -0.196486051671\n",
      "model 2 variable JM_estadocivil4 has weight of -0.176445352265\n",
      "model 2 variable eviv2 has weight of -0.165235135076\n",
      "model 2 variable tipovivi2 has weight of -0.165030776165\n",
      "model 2 variable Total Sum Years of Schooling has weight of -0.161313704848\n",
      "model 2 variable elimbasu6 has weight of -0.157668485442\n",
      "model 2 variable JM_parentesco2 has weight of -0.14646296738\n",
      "model 2 variable abastaguafuera has weight of -0.136860705086\n",
      "model 2 variable coopele has weight of -0.132948711196\n",
      "model 2 variable r4t1 has weight of -0.119417242113\n",
      "model 2 variable JM_parentesco5 has weight of -0.115734505369\n",
      "model 2 variable paredblolad has weight of -0.115416490791\n",
      "model 2 variable public has weight of -0.112489681772\n",
      "model 2 variable r4m1 has weight of -0.109469115958\n",
      "model 2 variable SQBhogar_nin has weight of -0.0941525173981\n",
      "model 2 variable area2 has weight of -0.0940911143964\n",
      "model 2 variable JM_parentesco11 has weight of -0.0873155998506\n",
      "model 2 variable sanitario5 has weight of -0.086356395707\n",
      "model 2 variable JM_Sum_Of_Males has weight of -0.0831766076346\n",
      "model 2 variable JM_3YrBehindSchool has weight of -0.0803683821691\n",
      "model 2 variable sanitario2 has weight of -0.0802470404962\n",
      "model 2 variable JM_1YrBehindSchool has weight of -0.076142603058\n",
      "model 2 variable SQBdependency has weight of -0.0755671142026\n",
      "model 2 variable JM_parentesco8 has weight of -0.0618481972544\n",
      "model 2 variable abastaguadentro has weight of -0.0597440816853\n",
      "model 2 variable SQBmeaned has weight of -0.0532135367008\n",
      "model 2 variable lugar1 has weight of -0.0481510428782\n",
      "model 2 variable tipovivi4 has weight of -0.0471349282404\n",
      "model 2 variable JM_estadocivil1 has weight of -0.0462447270425\n",
      "model 2 variable hacapo has weight of -0.0390604369315\n",
      "model 2 variable JM_4YrBehindSchool has weight of -0.0366863399006\n",
      "model 2 variable JM_estadocivil5 has weight of -0.0354802041481\n",
      "model 2 variable paredmad has weight of -0.0273826999398\n",
      "model 2 variable v14a has weight of -0.020766481685\n",
      "model 2 variable JM_parentesco10 has weight of -0.0206936337768\n",
      "model 2 variable lugar6 has weight of -0.0203895364351\n",
      "model 2 variable television has weight of -0.0175716639181\n",
      "model 2 variable cielorazo has weight of -0.0142036888102\n",
      "model 2 variable paredzinc has weight of -0.0129290481895\n",
      "model 2 variable tipovivi3 has weight of -0.00908918520104\n",
      "model 2 variable lugar2 has weight of -0.0088730959688\n",
      "model 2 variable lugar5 has weight of -0.00263993510168\n",
      "model 2 variable energcocinar1 has weight of -0.00108561559784\n",
      "model 2 variable dependency has weight of 8.56595784494e-05\n",
      "model 2 variable etecho3 has weight of 0.000827164125013\n",
      "model 2 variable JM_estadocivil6 has weight of 0.0104253271621\n",
      "model 2 variable JM_parentesco12 has weight of 0.0174753989692\n",
      "model 2 variable JM_2YrBehindSchool has weight of 0.0227624592349\n",
      "model 2 variable JM_instlevel7 has weight of 0.025191841101\n",
      "model 2 variable JM_estadocivil7 has weight of 0.0318816623839\n",
      "model 2 variable planpri has weight of 0.0353488769169\n",
      "model 2 variable JM_instlevel6 has weight of 0.0364447096261\n",
      "model 2 variable JM_parentesco9 has weight of 0.0373539466374\n",
      "model 2 variable JM_parentesco7 has weight of 0.041031968781\n",
      "model 2 variable JM_parentesco4 has weight of 0.0424555587142\n",
      "model 2 variable paredzocalo has weight of 0.0441087778116\n",
      "model 2 variable epared3 has weight of 0.0455842127113\n",
      "model 2 variable elimbasu3 has weight of 0.048656412225\n",
      "model 2 variable tipovivi1 has weight of 0.0526728328824\n",
      "model 2 variable lugar3 has weight of 0.0554476557058\n",
      "model 2 variable pisonotiene has weight of 0.0555186537372\n",
      "model 2 variable etecho1 has weight of 0.059366910807\n",
      "model 2 variable lugar4 has weight of 0.0682882201845\n",
      "model 2 variable JM_People_Educ_LT5 has weight of 0.0722652479032\n",
      "model 2 variable energcocinar3 has weight of 0.077979865439\n",
      "model 2 variable JM_estadocivil3 has weight of 0.0863120273845\n",
      "model 2 variable JM_mobilephone has weight of 0.0867343090885\n",
      "model 2 variable energcocinar4 has weight of 0.0881191070266\n",
      "model 2 variable edjefa has weight of 0.089397433827\n",
      "model 2 variable epared2 has weight of 0.0901458238901\n",
      "model 2 variable JM_instlevel4 has weight of 0.0938874031116\n",
      "model 2 variable area1 has weight of 0.0940911143964\n",
      "model 2 variable bedrooms has weight of 0.0954333989234\n",
      "model 2 variable JM_People_Educ_LT25 has weight of 0.108609117017\n",
      "model 2 variable tipovivi5 has weight of 0.113660777232\n",
      "model 2 variable JM_instlevel8 has weight of 0.114798025525\n",
      "model 2 variable JM_People_Educ_LT20 has weight of 0.115384235538\n",
      "model 2 variable pisomadera has weight of 0.120450790112\n",
      "model 2 variable JM_instlevel5 has weight of 0.125463907869\n",
      "model 2 variable JM_parentesco6 has weight of 0.136132975702\n",
      "model 2 variable meaneduc has weight of 0.138141540697\n",
      "model 2 variable JM_instlevel2 has weight of 0.148145115625\n",
      "model 2 variable JM_instlevel1 has weight of 0.153943312615\n",
      "model 2 variable JM_parentesco3 has weight of 0.156742480096\n",
      "model 2 variable JM_instlevel3 has weight of 0.157310333133\n",
      "model 2 variable JM_estadocivil2 has weight of 0.182393402839\n",
      "model 2 variable tamviv has weight of 0.185986823388\n",
      "model 2 variable JM_Sum_of_Disabled has weight of 0.238867364654\n",
      "model 2 variable JM_Sum_Of_Females has weight of 0.241514562914\n",
      "model 2 variable hogar_mayor has weight of 0.252348367567\n",
      "model 2 variable JM_People_Educ_LT10 has weight of 0.28396522861\n",
      "model 2 variable SQBovercrowding has weight of 0.39789486991\n",
      "model 2 variable edjefe has weight of 0.414553755291\n",
      "model 2 variable JM_People_Educ_LT15 has weight of 0.730791213934\n",
      "model 3 variable SQBhogar_nin has weight of -0.701618303293\n",
      "model 3 variable hogar_adul has weight of -0.658502323896\n",
      "model 3 variable JM_instlevel9 has weight of -0.559707766734\n",
      "model 3 variable paredzinc has weight of -0.479987163293\n",
      "model 3 variable JM_People_Educ_LT10 has weight of -0.479585677821\n",
      "model 3 variable SQBmeaned has weight of -0.39838781886\n",
      "model 3 variable JM_instlevel8 has weight of -0.305909511041\n",
      "model 3 variable SQBovercrowding has weight of -0.261098931903\n",
      "model 3 variable SQBescolari has weight of -0.240817136624\n",
      "model 3 variable v18q1 has weight of -0.198042590627\n",
      "model 3 variable JM_mobilephone has weight of -0.196058719712\n",
      "model 3 variable etecho3 has weight of -0.19104448369\n",
      "model 3 variable lugar6 has weight of -0.173230327795\n",
      "model 3 variable elimbasu6 has weight of -0.170950005979\n",
      "model 3 variable SQBdependency has weight of -0.169765895924\n",
      "model 3 variable JM_4YrBehindSchool has weight of -0.166890257337\n",
      "model 3 variable edjefe has weight of -0.165455414657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 3 variable JM_People_Educ_LT5 has weight of -0.149775761001\n",
      "model 3 variable meaneduc has weight of -0.143782450067\n",
      "model 3 variable JM_instlevel5 has weight of -0.143702673724\n",
      "model 3 variable abastaguafuera has weight of -0.143037171183\n",
      "model 3 variable sanitario2 has weight of -0.141653046571\n",
      "model 3 variable JM_instlevel7 has weight of -0.138157192843\n",
      "model 3 variable hhsize has weight of -0.13746673206\n",
      "model 3 variable hogar_total has weight of -0.13746673206\n",
      "model 3 variable JM_5YrBehindSchool has weight of -0.136439375116\n",
      "model 3 variable qmobilephone has weight of -0.124408824198\n",
      "model 3 variable edjefa has weight of -0.122159826944\n",
      "model 3 variable hogar_mayor has weight of -0.118346437944\n",
      "model 3 variable paredzocalo has weight of -0.109749783553\n",
      "model 3 variable abastaguadentro has weight of -0.107674221881\n",
      "model 3 variable JM_estadocivil2 has weight of -0.103294410607\n",
      "model 3 variable energcocinar4 has weight of -0.101974758854\n",
      "model 3 variable paredblolad has weight of -0.0915248730214\n",
      "model 3 variable bedrooms has weight of -0.0889280499242\n",
      "model 3 variable r4m1 has weight of -0.0851363653311\n",
      "model 3 variable tipovivi2 has weight of -0.0821377924345\n",
      "model 3 variable cielorazo has weight of -0.0732626721467\n",
      "model 3 variable energcocinar3 has weight of -0.0707323077378\n",
      "model 3 variable JM_estadocivil3 has weight of -0.0695863488668\n",
      "model 3 variable planpri has weight of -0.056252957705\n",
      "model 3 variable lugar4 has weight of -0.0529588842542\n",
      "model 3 variable JM_parentesco7 has weight of -0.0515916153875\n",
      "model 3 variable JM_parentesco6 has weight of -0.0509867717315\n",
      "model 3 variable JM_parentesco11 has weight of -0.0483001126341\n",
      "model 3 variable r4t1 has weight of -0.0417010091166\n",
      "model 3 variable JM_2YrBehindSchool has weight of -0.0315334922378\n",
      "model 3 variable tipovivi5 has weight of -0.0233474283307\n",
      "model 3 variable area1 has weight of -0.0202545471787\n",
      "model 3 variable paredmad has weight of -0.0186310529919\n",
      "model 3 variable television has weight of -0.0150348116054\n",
      "model 3 variable v14a has weight of -0.00707056211138\n",
      "model 3 variable tipovivi3 has weight of -0.00685378957681\n",
      "model 3 variable hacdor has weight of -0.0041991524856\n",
      "model 3 variable elimbasu3 has weight of -0.00323410683071\n",
      "model 3 variable techocane has weight of -0.000363921743252\n",
      "model 3 variable JM_instlevel3 has weight of 0.00319287026376\n",
      "model 3 variable etecho1 has weight of 0.0080863950583\n",
      "model 3 variable lugar5 has weight of 0.0159222401998\n",
      "model 3 variable JM_parentesco12 has weight of 0.0162394455301\n",
      "model 3 variable JM_parentesco10 has weight of 0.0170914849518\n",
      "model 3 variable area2 has weight of 0.0202545471787\n",
      "model 3 variable lugar2 has weight of 0.0258379556172\n",
      "model 3 variable JM_Sum_of_Disabled has weight of 0.0263439753318\n",
      "model 3 variable overcrowding has weight of 0.0266783541273\n",
      "model 3 variable rooms has weight of 0.0275294679365\n",
      "model 3 variable JM_parentesco8 has weight of 0.0342302300652\n",
      "model 3 variable lugar1 has weight of 0.0348781073173\n",
      "model 3 variable pisonotiene has weight of 0.038186009415\n",
      "model 3 variable JM_instlevel4 has weight of 0.0394738615959\n",
      "model 3 variable JM_Sum_Of_Males has weight of 0.0414171147411\n",
      "model 3 variable JM_estadocivil4 has weight of 0.0487994535708\n",
      "model 3 variable JM_1YrBehindSchool has weight of 0.052261264242\n",
      "model 3 variable tipovivi1 has weight of 0.0535517244988\n",
      "model 3 variable epared2 has weight of 0.0558013676133\n",
      "model 3 variable JM_parentesco3 has weight of 0.0559686532275\n",
      "model 3 variable tipovivi4 has weight of 0.057187017136\n",
      "model 3 variable energcocinar1 has weight of 0.0605979516177\n",
      "model 3 variable JM_parentesco9 has weight of 0.0614722033131\n",
      "model 3 variable pisomadera has weight of 0.0652082223916\n",
      "model 3 variable sanitario5 has weight of 0.0683498839467\n",
      "model 3 variable JM_estadocivil5 has weight of 0.0711306550876\n",
      "model 3 variable JM_instlevel6 has weight of 0.0792218267601\n",
      "model 3 variable JM_3YrBehindSchool has weight of 0.0799269903717\n",
      "model 3 variable JM_parentesco4 has weight of 0.0833652027645\n",
      "model 3 variable JM_instlevel2 has weight of 0.0927636712563\n",
      "model 3 variable JM_parentesco5 has weight of 0.0963503087632\n",
      "model 3 variable eviv2 has weight of 0.124312118383\n",
      "model 3 variable lugar3 has weight of 0.126114636447\n",
      "model 3 variable eviv3 has weight of 0.135857584204\n",
      "model 3 variable JM_estadocivil7 has weight of 0.138372865933\n",
      "model 3 variable SQBhogar_total has weight of 0.142997005372\n",
      "model 3 variable hacapo has weight of 0.144790824162\n",
      "model 3 variable JM_People_Educ_LT25 has weight of 0.145509098272\n",
      "model 3 variable JM_People_Educ_LT20 has weight of 0.148342303003\n",
      "model 3 variable JM_instlevel1 has weight of 0.156568385015\n",
      "model 3 variable JM_estadocivil1 has weight of 0.165561677301\n",
      "model 3 variable Total Sum Years of Schooling has weight of 0.169471545533\n",
      "model 3 variable epared3 has weight of 0.173404484768\n",
      "model 3 variable JM_Sum_Of_Females has weight of 0.173773876207\n",
      "model 3 variable JM_estadocivil6 has weight of 0.179315092311\n",
      "model 3 variable JM_parentesco2 has weight of 0.30843671025\n",
      "model 3 variable tamviv has weight of 0.309562476962\n",
      "model 3 variable SQBedjefe has weight of 0.392221547523\n",
      "model 3 variable dependency has weight of 0.497996605219\n",
      "model 3 variable public has weight of 0.715957755412\n",
      "model 3 variable coopele has weight of 0.777343246834\n",
      "model 3 variable JM_People_Educ_LT15 has weight of 1.00465362518\n",
      "model 4 variable JM_People_Educ_LT15 has weight of -1.18743863622\n",
      "model 4 variable public has weight of -0.522455335323\n",
      "model 4 variable coopele has weight of -0.514077939156\n",
      "model 4 variable dependency has weight of -0.452810163601\n",
      "model 4 variable JM_instlevel1 has weight of -0.395400076641\n",
      "model 4 variable JM_instlevel2 has weight of -0.333916367073\n",
      "model 4 variable JM_Sum_Of_Females has weight of -0.328186266079\n",
      "model 4 variable tamviv has weight of -0.283769240928\n",
      "model 4 variable overcrowding has weight of -0.279323683006\n",
      "model 4 variable Total Sum Years of Schooling has weight of -0.262357556061\n",
      "model 4 variable SQBmeaned has weight of -0.229469179066\n",
      "model 4 variable JM_estadocivil1 has weight of -0.212606575808\n",
      "model 4 variable JM_People_Educ_LT20 has weight of -0.199791816983\n",
      "model 4 variable JM_Sum_of_Disabled has weight of -0.196777570414\n",
      "model 4 variable JM_People_Educ_LT25 has weight of -0.19405393722\n",
      "model 4 variable JM_estadocivil7 has weight of -0.182427530454\n",
      "model 4 variable JM_parentesco3 has weight of -0.176904110662\n",
      "model 4 variable JM_parentesco2 has weight of -0.155173158346\n",
      "model 4 variable JM_instlevel3 has weight of -0.146424885791\n",
      "model 4 variable lugar3 has weight of -0.146239231381\n",
      "model 4 variable JM_instlevel4 has weight of -0.143469853567\n",
      "model 4 variable pisomadera has weight of -0.125811479359\n",
      "model 4 variable SQBedjefe has weight of -0.105163459661\n",
      "model 4 variable tipovivi1 has weight of -0.104908225988\n",
      "model 4 variable energcocinar1 has weight of -0.104410543097\n",
      "model 4 variable pisonotiene has weight of -0.102570457857\n",
      "model 4 variable epared3 has weight of -0.0935403425711\n",
      "model 4 variable area1 has weight of -0.0850551944314\n",
      "model 4 variable etecho1 has weight of -0.0842297918477\n",
      "model 4 variable tipovivi5 has weight of -0.0786947562701\n",
      "model 4 variable edjefe has weight of -0.0757378509866\n",
      "model 4 variable energcocinar4 has weight of -0.0732561803198\n",
      "model 4 variable JM_estadocivil5 has weight of -0.0728174106328\n",
      "model 4 variable edjefa has weight of -0.0728089034099\n",
      "model 4 variable bedrooms has weight of -0.0714051350634\n",
      "model 4 variable planpri has weight of -0.0635215555918\n",
      "model 4 variable epared2 has weight of -0.0593417827873\n",
      "model 4 variable lugar4 has weight of -0.0592630286202\n",
      "model 4 variable JM_instlevel6 has weight of -0.0565108603264\n",
      "model 4 variable hacapo has weight of -0.0542679081095\n",
      "model 4 variable elimbasu3 has weight of -0.0509882618854\n",
      "model 4 variable tipovivi4 has weight of -0.0503475918627\n",
      "model 4 variable JM_parentesco5 has weight of -0.0474437061316\n",
      "model 4 variable JM_parentesco11 has weight of -0.0374767828742\n",
      "model 4 variable JM_estadocivil6 has weight of -0.0303804569525\n",
      "model 4 variable JM_2YrBehindSchool has weight of -0.0302633709936\n",
      "model 4 variable energcocinar3 has weight of -0.0203110681297\n",
      "model 4 variable lugar2 has weight of -0.0186423931132\n",
      "model 4 variable SQBhogar_nin has weight of -0.0166168916364\n",
      "model 4 variable hogar_mayor has weight of -0.0133222302872\n",
      "model 4 variable JM_parentesco8 has weight of -0.0115344788913\n",
      "model 4 variable JM_parentesco6 has weight of -0.0113598400072\n",
      "model 4 variable JM_parentesco9 has weight of -0.00752657444337\n",
      "model 4 variable JM_parentesco4 has weight of -0.00570776875499\n",
      "model 4 variable JM_parentesco7 has weight of -0.00478652950791\n",
      "model 4 variable JM_parentesco10 has weight of 0.00327713970062\n",
      "model 4 variable paredmad has weight of 0.00968777880962\n",
      "model 4 variable rooms has weight of 0.0111950966543\n",
      "model 4 variable JM_3YrBehindSchool has weight of 0.0146041744877\n",
      "model 4 variable lugar5 has weight of 0.0162591692172\n",
      "model 4 variable JM_instlevel5 has weight of 0.0180473546976\n",
      "model 4 variable JM_1YrBehindSchool has weight of 0.0184810619993\n",
      "model 4 variable JM_parentesco12 has weight of 0.0203619431871\n",
      "model 4 variable techocane has weight of 0.0219420990062\n",
      "model 4 variable abastaguadentro has weight of 0.0324438687114\n",
      "model 4 variable JM_estadocivil2 has weight of 0.0326753959041\n",
      "model 4 variable hacdor has weight of 0.03288965528\n",
      "model 4 variable sanitario5 has weight of 0.0365264458936\n",
      "model 4 variable paredzocalo has weight of 0.0374219308007\n",
      "model 4 variable JM_4YrBehindSchool has weight of 0.0406373440193\n",
      "model 4 variable v14a has weight of 0.0413455955738\n",
      "model 4 variable television has weight of 0.0419978109075\n",
      "model 4 variable lugar1 has weight of 0.0425098886897\n",
      "model 4 variable JM_Sum_Of_Males has weight of 0.0431716356662\n",
      "model 4 variable r4t1 has weight of 0.0470346065952\n",
      "model 4 variable JM_estadocivil3 has weight of 0.0485638628399\n",
      "model 4 variable JM_instlevel7 has weight of 0.050264718369\n",
      "model 4 variable JM_People_Educ_LT5 has weight of 0.0521460230675\n",
      "model 4 variable JM_5YrBehindSchool has weight of 0.0601632114925\n",
      "model 4 variable eviv2 has weight of 0.0740394241937\n",
      "model 4 variable JM_estadocivil4 has weight of 0.08300116667\n",
      "model 4 variable JM_instlevel8 has weight of 0.0839303339137\n",
      "model 4 variable area2 has weight of 0.0850551944314\n",
      "model 4 variable abastaguafuera has weight of 0.100149671015\n",
      "model 4 variable cielorazo has weight of 0.101400976998\n",
      "model 4 variable tipovivi3 has weight of 0.103464168232\n",
      "model 4 variable lugar6 has weight of 0.121301210278\n",
      "model 4 variable paredzinc has weight of 0.127746012859\n",
      "model 4 variable tipovivi2 has weight of 0.134822856881\n",
      "model 4 variable r4m1 has weight of 0.136084219162\n",
      "model 4 variable etecho3 has weight of 0.144126412715\n",
      "model 4 variable JM_mobilephone has weight of 0.167063860652\n",
      "model 4 variable SQBhogar_total has weight of 0.170015090916\n",
      "model 4 variable sanitario2 has weight of 0.176994261652\n",
      "model 4 variable paredblolad has weight of 0.1833171294\n",
      "model 4 variable eviv3 has weight of 0.192612412078\n",
      "model 4 variable elimbasu6 has weight of 0.215705392818\n",
      "model 4 variable SQBovercrowding has weight of 0.250358227941\n",
      "model 4 variable JM_People_Educ_LT10 has weight of 0.254155097227\n",
      "model 4 variable v18q1 has weight of 0.266198588646\n",
      "model 4 variable SQBdependency has weight of 0.347671559968\n",
      "model 4 variable qmobilephone has weight of 0.391716343094\n",
      "model 4 variable SQBescolari has weight of 0.397741404903\n",
      "model 4 variable meaneduc has weight of 0.628668198406\n",
      "model 4 variable hhsize has weight of 0.664446951435\n",
      "model 4 variable hogar_total has weight of 0.664446951435\n",
      "model 4 variable JM_instlevel9 has weight of 0.692079740381\n",
      "model 4 variable hogar_adul has weight of 0.789376893467\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Feature Importance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train2)\n",
    "\n",
    "\n",
    "#Scale the features so that features are on an equal scale for feature interpretation\n",
    "X_train_scaled = scl_obj.transform(X_train2)\n",
    "X_test_scaled = scl_obj.transform(X_test2) \n",
    "\n",
    "\n",
    "lr_clf = LogisticRegression(C=1,  class_weight=None)\n",
    "lr_clf.fit(X_train_scaled,y_train)\n",
    "\n",
    "y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "#coeff = lr_clf.coef_\n",
    "\n",
    "for num in range(4):\n",
    "    zip_vars = zip(lr_clf.coef_[num].T,X_train2.columns) # combine attributes\n",
    "    zip_vars = sorted(zip_vars)\n",
    "    #print(zip_vars)\n",
    "    for coef, name in zip_vars:\n",
    "        print(\"model\",num+1,\"variable\",name, 'has weight of', coef)\n",
    "#print(zip_vars)\n",
    "#print(coef)\n",
    "#wtf - can't figure out how to sort this.  following example and it blows up. \n",
    "#zip_vars = sorted(zip_vars)\n",
    "\n",
    "#for coef, name in zip_vars:\n",
    " #     for cnt in range(4):\n",
    "  #      print(name, 'has weight of', coef[cnt])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Scikit learn logistic regression, the default setting is one vs. all methdology for a multi-class dependent variable. In our case, we have 4 different classes 1,2,3,and 4 where 1 is extreme poverty and 4 non-vulnerable households. Some variables are dropped from the model because of redundancy and/or contribution to the total variation is small. After adjusting for the variation in each of the explanatory variables, importance can now be interpreted. This is because of the large amount of variables being used so we are only looking at the top 3 negatively and positively correlated features. \n",
    "\n",
    "When looking at the first model, extreme poverty vs. all, we can see that overcrowding square, qmobilephone, and mean education are high importance on the negative end. On the positive end, people with education less than 15 years, public electricity, and overcrowding are high importance.In the case of extreme poverty, overcrowding and education seem to be overarching theme of extreme poverty. Increase in mean education and number of mobile phones indicates a lower likelihood of not being in poverty, where we can say number of mobile phones is proxy for income of the household. Increase in the number of people with less than 15 years of education, use of public electricity, and overcrowding indicates a higher likelihood of being in extreme poverty, where public electricity could be a proxy for income of the household also.\n",
    "\n",
    "When looking at the second model, moderate poverty vs. all, we can see that on the negative end number of adults in the household, education of the male head of household squared, and number of post-graduates or higher are of high importance. This seems to be indicate that higher number of adults, education of the male of household squares, and post graduate degrees decreases the likelihood of being in moderate poverty. On the postive end, we can see people with education less than 15 years, education of the male head of household, and overcrowding square are of high importance. We see the same variable overcrowding and people with education less than 15 years, that increases in these variable will increase the likehood of being in moderate poverty. The square of overcrowding could indicate a quadratic relationship indicating a minimum of overcrowding can increase the liklihood of moderate poverty.\n",
    "\n",
    "When looking at the third model,vulnerable household vs. all, number of children between 0 to 19 squared, number of adults in the household, and post graduate degrees are of high importance on the negative end. The reoccurring theme of higher education lowers the likelihood of being in a vulnerable household is present. It seems to also shows that there could be a maximum of number of children which could decrease the likelihood of being in a vulnerable household. Also having more adults in the household decreases the likelihood of being in vulnerable household since this could be a proxy for more income. On the positive end, people with education less than 15 years, use of electricity from cooperative, and use of public electricity are of high importance. It seems to show that having less than 15 years of education significantly increases your likelihood of being in a vulnerable household. Also what kind of electricity you can afford, public and cooperative, is a proxy of income and so using these types of electricity means lower income which mean higher likelihood of being in a vulnerable household.\n",
    "\n",
    "When looking at the fourth model, non-vulnerable households vs all, we can see that people with education less than 15 years, use of electricity from cooperative, and use of public electricity are of high importance. This is the exact oppositive of the vulnerable household. If the household has any of these indicators then they have a lower likelihood of being a non-vulnerable household. On the positive end, number of adults in the household, number of postgraudate degrees, and number of individuals in the household indicate a higher likelihood of being in a non-vulnerable household. This is intuitive because the more adults could mean more income, having a postgraduate degree means a higher paying job, and more individuals in the household means the household is able to afford the high cost that comes with large households.\n",
    "\n",
    "Some variables are more important than others because of how prevalent the characteristic is for the given level. We can see that overcrowding is prevelant in the extreme and moderate poverty levels but not in the vulnerable and non-vulnerable levels. This indicates there are more people with type of characteristic at those poverty levels. However, there is an overarching theme that education is good indicator for poverty levels. In that each poverty level has some type of education variable. This seems to show that there is a certain threshold of education that can determine what is the likelihood of a given poverty level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Support Vectors\n",
    "\n",
    "Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain. If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model then analyze the support vectors from the subsampled dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using linear for SVM on our dataset, it takes high computational power and time to obtain an answer. In our case, we waited for a long time and results cannot be obtained for the support vectors when using all variables in the estimation. Because of this, RBF kernel is used and classification can be applied to the dataset, which gives the accuracy and the confusion matrix. Since the RBF kernel is used the support vectors cannot be estimated because it goes to higher dimensions which is mathmatically not possible to estimate. Therefore, no estimations on weight and no insight cannot be gained into the data.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
