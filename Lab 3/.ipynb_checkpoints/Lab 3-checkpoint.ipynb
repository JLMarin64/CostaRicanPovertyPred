{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "### Authors: Jason Lin, Jason Lingle, Jonathan Marin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "- [ ] Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). \n",
    "- [ ] How will you measure the effectiveness of a good algorithm? \n",
    "- [ ] Why does your chosen validation method make sense for this specific dataset and the stakeholders needs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue of poverty is an issue in even the wealthiest of countries such as the United States.  While countries have their own way of providing support to individuals in need, the issue of identifying people with the most needs is always an issue.  Many social programs have a hard time making sure the right people are given enough aid. It is especially difficult when a program focuses on the poorest segment of the population as they are unable to provide the income and expense records that are typically required for qualification.\n",
    "\n",
    "In Latin America, a common method of verifying income qualification when income data is unavailable or unreliable is the Proxy Means Test (PMT).  With PMT, agencies use a model that considers a family’s observable household attributes like the material of their walls and ceiling, or the assets found in the home to classify them and predict their level of need.  While this test is better at evaluating income needs over other methods, the accuracy of predicting income qualification remains a problem as the region’s population grows and poverty declines.\n",
    "\n",
    "With this backdrop, our team has selected a data set called the “Costa Rican Household Poverty Level Prediction” from Kaggle.  The data set has been provided by the Inter-American Development Bank (IDB), which is the largest source of development financing for Latin American and Caribbean countries.  The goal of the IDB in providing this data set is to get support in improving income qualification for some of the world's poorest families for social welfare assistance in Latin America. (https://www.kaggle.com/c/costa-rican-household-poverty-prediction).  It is also their belief that new methods, beyond traditional econometrics, might be identified that could improve PMT performance.\n",
    "The dataset is a file with household characteristics from a sample of Costa Rican households from an unknown year. The dataset has observations for each member of the household, but the classification is done at the household level. The target is an ordinal variable indicating groups of income levels:\n",
    "\n",
    "•\t1 = extreme poverty\n",
    "•\t2 = moderate poverty\n",
    "•\t3 = vulnerable households\n",
    "•\t4 = non-vulnerable households\n",
    "\n",
    "The goal is to use the household characteristics provided and possibly create new features to group the income levels using clustering. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding 1\n",
    "\n",
    "- [ ] Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. \n",
    "- [ ] Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? \n",
    "- [ ] How do you deal with these problems?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Meaning Type\n",
    "\n",
    "\n",
    "Variable Name | Definition | Variable Type\n",
    "--------------|------------|------------------|\n",
    "v2a1 |  Monthly rent payment | float\n",
    "hacdor |  =1 Overcrowding by bedrooms | bool\n",
    "rooms |   number of all rooms in the house | int\n",
    "hacapo |  =1 Overcrowding by rooms | bool\n",
    "v14a |  =1 has bathroom in the household | bool\n",
    "refrig |  =1 if the household has refrigerator | bool\n",
    "v18q |  owns a tablet | bool\n",
    "v18q1 |  number of tablets household owns | int\n",
    "r4h1 |  Males younger than 12 years of age | int\n",
    "r4h2 |  Males 12 years of age and older | int\n",
    "r4h3 |  Total males in the household | int\n",
    "r4m1 |  Females younger than 12 years of age | int\n",
    "r4m2 |  Females 12 years of age and older | int\n",
    "r4m3 |  Total females in the household | int\n",
    "r4t1 |  persons younger than 12 years of age | int\n",
    "r4t2 |  persons 12 years of age and older | int\n",
    "r4t3 |  Total persons in the household | int\n",
    "tamhog |  size of the household | int\n",
    "tamviv |  number of persons living in the household | int\n",
    "escolari |  years of schooling | int\n",
    "rez_esc |  Years behind in school | int\n",
    "hhsize |  household size | int\n",
    "paredblolad |  =1 if predominant material on the outside wall is block or brick | bool\n",
    "paredzocalo |  \"=1 if predominant material on the outside wall is socket (wood   zinc or absbesto\" | bool\n",
    "paredpreb |  =1 if predominant material on the outside wall is prefabricated or cement | bool\n",
    "pareddes |  =1 if predominant material on the outside wall is waste material | bool\n",
    "paredmad |  =1 if predominant material on the outside wall is wood | bool\n",
    "paredzinc |  =1 if predominant material on the outside wall is zink | bool\n",
    "paredfibras |  =1 if predominant material on the outside wall is natural fibers | bool\n",
    "paredother |  =1 if predominant material on the outside wall is other | bool\n",
    "pisomoscer |  \"=1 if predominant material on the floor is mosaic, ceramic, terrzo | bool\n",
    "pisocemento |  =1 if predominant material on the floor is cement | bool\n",
    "pisoother |  =1 if predominant material on the floor is other | bool\n",
    "pisonatur |  =1 if predominant material on the floor is  natural material | bool\n",
    "pisonotiene |  =1 if no floor at the household | bool\n",
    "pisomadera |  =1 if predominant material on the floor is wood | bool\n",
    "techozinc |  =1 if predominant material on the roof is metal foil or zink | bool\n",
    "techoentrepiso |  \"=1 if predominant material on the roof is fiber cement   mezzanine | bool\n",
    "techocane |  =1 if predominant material on the roof is natural fibers | bool\n",
    "techootro |  =1 if predominant material on the roof is other | bool\n",
    "cielorazo |  =1 if the house has ceiling | bool\n",
    "abastaguadentro |  =1 if water provision inside the dwelling | bool\n",
    "abastaguafuera |  =1 if water provision outside the dwelling | bool\n",
    "abastaguano |  =1 if no water provision | bool\n",
    "public |  \"=1 electricity from CNFL   ICE  ESPH/JASEC | bool\n",
    "planpri |  =1 electricity from private plant | bool\n",
    "noelec |  =1 no electricity in the dwelling | bool\n",
    "coopele |  =1 electricity from cooperative | bool\n",
    "sanitario1 |  =1 no toilet in the dwelling | bool\n",
    "sanitario2 |  =1 toilet connected to sewer or cesspool | bool\n",
    "sanitario3 |  =1 toilet connected to  septic tank | bool\n",
    "sanitario5 |  =1 toilet connected to black hole or letrine | bool\n",
    "sanitario6 |  =1 toilet connected to other system | bool\n",
    "energcocinar1 |  =1 no main source of energy used for cooking (no kitchen) | bool\n",
    "energcocinar2 |  =1 main source of energy used for cooking electricity | bool\n",
    "energcocinar3 |  =1 main source of energy used for cooking gas | bool\n",
    "energcocinar4 |  =1 main source of energy used for cooking wood charcoal | bool\n",
    "elimbasu1 |  =1 if rubbish disposal mainly by tanker truck | bool\n",
    "elimbasu2 |  =1 if rubbish disposal mainly by botan hollow or buried | bool\n",
    "elimbasu3 |  =1 if rubbish disposal mainly by burning | bool\n",
    "elimbasu4 |  =1 if rubbish disposal mainly by throwing in an unoccupied space | bool\n",
    "elimbasu5 |  \"=1 if rubbish disposal mainly by throwing in river | bool\n",
    "elimbasu6 |  =1 if rubbish disposal mainly other | bool\n",
    "epared1 |  =1 if walls are bad | bool\n",
    "epared2 |  =1 if walls are regular | bool\n",
    "epared3 |  =1 if walls are good | bool\n",
    "etecho1 |  =1 if roof are bad | bool\n",
    "etecho2 |  =1 if roof are regular | bool\n",
    "etecho3 |  =1 if roof are good | bool\n",
    "eviv1 |  =1 if floor are bad | bool\n",
    "eviv2 |  =1 if floor are regular | bool\n",
    "eviv3 |  =1 if floor are good | bool\n",
    "dis |  =1 if disable person | bool\n",
    "male |  =1 if male | bool\n",
    "female |  =1 if female | bool\n",
    "estadocivil1 |  =1 if less than 10 years old | bool\n",
    "estadocivil2 |  =1 if free or coupled uunion | bool\n",
    "estadocivil3 |  =1 if married | bool\n",
    "estadocivil4 |  =1 if divorced | bool\n",
    "estadocivil5 |  =1 if separated | bool\n",
    "estadocivil6 |  =1 if widow/er | bool\n",
    "estadocivil7 |  =1 if single | bool\n",
    "parentesco1 |  =1 if household head | bool\n",
    "parentesco2 |  =1 if spouse/partner | bool\n",
    "parentesco3 |  =1 if son/doughter | bool\n",
    "parentesco4 |  =1 if stepson/doughter | bool\n",
    "parentesco5 |  =1 if son/doughter in law | bool\n",
    "parentesco6 |  =1 if grandson/doughter | bool\n",
    "parentesco7 |  =1 if mother/father | bool\n",
    "parentesco8 |  =1 if father/mother in law | bool\n",
    "parentesco9 |  =1 if brother/sister | bool\n",
    "parentesco10 |  =1 if brother/sister in law | bool\n",
    "parentesco11 |  =1 if other family member | bool\n",
    "parentesco12 |  =1 if other non family member | bool\n",
    "idhogar |  Household level identifier | string\n",
    "hogar_nin |  Number of children 0 to 19 in household | int\n",
    "hogar_adul |  Number of adults in household | int\n",
    "hogar_mayor |  # of individuals 65+ in the household | int\n",
    "hogar_total |  # of total individuals in the household | int\n",
    "dependency |  Dependency rate,  calculated = (number of members of the household younger than 19 or older than 64)/(number of member of household between 19 and 64) | numeric\n",
    "edjefe |  years of education of male head of household,  based on the interaction of escolari (years of education)  head of household and gender,  yes=1 and no=0 | bool\n",
    "edjefa |  years of education of female head of household , based on the interaction of escolari (years of education) , head of household and gender,  yes=1 and no=0 | bool\n",
    "meaneduc | average years of education for adults (18+) | int\n",
    "instlevel1 |  =1 no level of education | bool\n",
    "instlevel2 |  =1 incomplete primary | bool\n",
    "instlevel3 |  =1 complete primary | bool\n",
    "instlevel4 |  =1 incomplete academic secondary level | bool\n",
    "instlevel5 |  =1 complete academic secondary level | bool\n",
    "instlevel6 |  =1 incomplete technical secondary level | bool\n",
    "instlevel7 |  =1 complete technical secondary level | bool\n",
    "instlevel8 |  =1 undergraduate and higher education | bool\n",
    "instlevel9 |  =1 postgraduate higher education | bool\n",
    "bedrooms |  number of bedrooms | int\n",
    "overcrowding |  # persons per room | int\n",
    "tipovivi1 |  =1 own and fully paid house | bool\n",
    "tipovivi2 |  \"=1 own paying in installments | bool\n",
    "tipovivi3 |  =1 rented | bool\n",
    "tipovivi4 |  =1 precarious | bool\n",
    "tipovivi5 |  \"=1 other(assigned   borrowed)\" | bool\n",
    "computer |  =1 if the household has notebook or desktop computer | bool\n",
    "television |  =1 if the household has TV | bool\n",
    "mobilephone |  =1 if mobile phone | bool\n",
    "qmobilephone |  # of mobile phones | int\n",
    "lugar1 |  =1 region Central | bool\n",
    "lugar2 |  =1 region Chorotega | bool\n",
    "lugar3 |  =1 region PacÃƒÂ­fico central | bool\n",
    "lugar4 |  =1 region Brunca | bool\n",
    "lugar5 |  =1 region Huetar AtlÃƒÂ¡ntica | bool\n",
    "lugar6 |  =1 region Huetar Norte | bool\n",
    "area1 |  =1 zona urbana | bool\n",
    "area2 |  =2 zona rural | bool\n",
    "age |  Age in years | int\n",
    "SQBescolari |  escolari squared | numeric\n",
    "SQBage |  age squared | numeric\n",
    "SQBhogar_total |  hogar_total squared | int\n",
    "SQBedjefe |  edjefe squared | int\n",
    "SQBhogar_nin |  hogar_nin squared | int\n",
    "SQBovercrowding |  overcrowding squared | float\n",
    "SQBdependency |  dependency squared | float\n",
    "SQBmeaned |  square of the mean years of education of adults (>=18) in the household | bool\n",
    "agesq |  Age squared | numeric\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Missing Data (NaNs)\n",
    "\n",
    "### v2a1\n",
    "This variable represents the Monthly Rent Payment.  This may be null because there is no monthly rent payment as the subjet may own the house in full (variable:tipovivi1).  When the home is owened in full, we populated the monthly payment as $0 instead of null.  However, there are blanks still in train and test after doing so.  It may be possible to build a prelimanary model to impute this with all the household and location characteristics that we already have, however, we have imputed the rest with the mean for the remaining nulls. \n",
    "\n",
    "\n",
    "### v18q1        \n",
    "This variable represents the number of people who own a tablet.  This is a member level variable and the imputation of this will be handled by the aggregation to household level.  We believe that the nulls here represent zero. \n",
    "\n",
    "### rez_esc\n",
    "This variable represents the number of years a member is behind in school.  This is a member level variable and the imputation of this will be hangled by the aggregation to household level.  We beleive that the nulls here represent zero. \n",
    "\n",
    "### meaneduc       \n",
    "\n",
    "This variable represents the average years of education adults (18+) have.  This is a household level variable.  We have imputed this by taking the number of years of eduction from the head of household males/females.  \n",
    "\n",
    "### SQBmeaned       \n",
    "\n",
    "This variable is the square of meaneduc which was null for the same columns that the meaneduc was null for.  This was calculated by squaring the imputed meaneduc. \n",
    "\n",
    "\n",
    "## Outliers\n",
    "\n",
    "\n",
    "\n",
    "## Errors\n",
    "\n",
    "The kaggle competition rules mentioned that the scoring only occurs on head of household, but member level data was provided.  We have found member level data tied to households that had no head of household.  These were excluded from the study since they will not be scored in the test set per kaggle rules. \n",
    "\n",
    "Also, meaneduc and SQBmeaned were not populated even though we had information on head of household education. \n",
    "\n",
    "\n",
    "## Denormalization \n",
    "\n",
    "Some variables of the dataset is at the member level and we are provided a key (variable: idhogar) that ties the member to the household.  The target should be the same between all members of the household.  If it is different, it is an error and we should use the head of household (variable: parentesco1) target. Note that the scoring on the test set within the kaggle competition is only done for heads of household.  The member level was provided for additional feature engineering. \n",
    "\n",
    "To overcome this, the plan would be to denormalize the data by head of household for both train and test for heads of household. Then, we will need to backfill the expected test set submission as it is expected to be submitted at the member level even though it is only scoring at the household level.  We believe that we can leave the members that are not heads of household blank in the submission according to what was stated in the kaggle submission selection.  \n",
    "\n",
    "\n",
    "Data Attributes spreadsheet was created to show attributes and member level or household level.  Variables were reviewed to assign each category appropriately.  For some fields, it was a simple sum, but for others, we created bins for the column and then summed.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Prework\n",
    "\n",
    "#Load Packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pandasql import sqldf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "\n",
    "train = pd.DataFrame(pd.read_csv(\"train.csv\"))\n",
    "test = pd.DataFrame(pd.read_csv(\"test.csv\"))\n",
    "\n",
    "\n",
    "\n",
    "#Find the Nulls\n",
    "null_columns=train.columns[train.isnull().any()]\n",
    "\n",
    "train[null_columns].isnull().sum()\n",
    "\n",
    "\n",
    "train.loc[(train.tipovivi1 == 1),'v2a1'] = 0\n",
    "test.loc[(test.tipovivi1 == 1),'v2a1'] = 0\n",
    "\n",
    "\n",
    "train.loc[np.isnan(train[\"v18q1\"]), 'v18q1'] = 0\n",
    "test.loc[np.isnan(test[\"v18q1\"]), 'v18q1'] = 0\n",
    "\n",
    "train.loc[np.isnan(train[\"v18q1\"]), 'v18q1'] = 0\n",
    "test.loc[np.isnan(test[\"v18q1\"]), 'v18q1'] = 0\n",
    "\n",
    "\n",
    "train.loc[(train.dependency == \"yes\"),'dependency'] = 1\n",
    "train.loc[(train.dependency == \"no\"),'dependency'] = 0\n",
    "\n",
    "test.loc[(test.dependency == \"yes\"),'dependency'] = 1\n",
    "test.loc[(test.dependency == \"no\"),'dependency'] = 0\n",
    "\n",
    "\n",
    "train.loc[(train.edjefe == \"yes\"),'edjefe'] = 1\n",
    "train.loc[(train.edjefe == \"no\"),'edjefe'] = 0\n",
    "\n",
    "test.loc[(test.edjefe == \"yes\"),'edjefe'] = 1\n",
    "test.loc[(test.edjefe == \"no\"),'edjefe'] = 0\n",
    "\n",
    "\n",
    "\n",
    "train.loc[(train.edjefa == \"yes\"),'edjefa'] = 1\n",
    "train.loc[(train.edjefa == \"no\"),'edjefa'] = 0\n",
    "\n",
    "test.loc[(test.edjefa == \"yes\"),'edjefa'] = 1\n",
    "test.loc[(test.edjefa == \"no\"),'edjefa'] = 0\n",
    "\n",
    "\n",
    "null_columns=train.columns[train.isnull().any()]\n",
    "\n",
    "train[null_columns].isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "#Create subset dataframes for head of househoold for tain and test\n",
    "train_head = train[['idhogar', 'parentesco1', 'Id', 'hhsize', 'v2a1', 'hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'v18q1', 'r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3', 'tamhog', 'tamviv', 'paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera', 'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', 'abastaguadentro', 'abastaguafuera', 'abastaguano', 'public', 'planpri', 'noelec', 'coopele', 'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6', 'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', 'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total', 'dependency', 'edjefe', 'edjefa', 'meaneduc', 'bedrooms', 'overcrowding', 'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', 'computer', 'television', 'qmobilephone', 'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6', 'area1', 'area2', 'SQBescolari', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned','Target']]\n",
    "\n",
    "train_head = train_head[train_head['parentesco1'] == 1]\n",
    "\n",
    "test_head = test[['idhogar', 'parentesco1', 'Id', 'hhsize', 'v2a1', 'hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'v18q1', 'r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3', 'tamhog', 'tamviv', 'paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera', 'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', 'abastaguadentro', 'abastaguafuera', 'abastaguano', 'public', 'planpri', 'noelec', 'coopele', 'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6', 'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', 'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total', 'dependency', 'edjefe', 'edjefa', 'meaneduc', 'bedrooms', 'overcrowding', 'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', 'computer', 'television', 'qmobilephone', 'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6', 'area1', 'area2', 'SQBescolari', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned']]\n",
    "\n",
    "test_head = test_head[test_head['parentesco1'] == 1]\n",
    "\n",
    "#Start the member level denormalization for train and test\n",
    "train_member_agg = pd.DataFrame(sqldf(\"select  \"\n",
    "\"idhogar, \"\n",
    "\"sum(cast(v18q as int)) 'JM_Sum_of_Tablets', \"\n",
    "\"sum(cast(escolari as int)) 'Total Sum Years of Schooling', \"\n",
    "\"sum(case when escolari < 5 then 1 else 0 end) as 'JM_People_Educ_LT5', \"\n",
    "\"sum(case when escolari < 10 then 1 else 0 end) as 'JM_People_Educ_LT10', \"\n",
    "\"sum(case when escolari < 15 then 1 else 0 end) as 'JM_People_Educ_LT15', \"\n",
    "\"sum(case when escolari < 20 then 1 else 0 end) as 'JM_People_Educ_LT20', \"\n",
    "\"sum(case when escolari < 25 then 1 else 0 end) as 'JM_People_Educ_LT25', \"\n",
    "\"sum(case when rez_esc = 1 then 1 else 0 end) as 'JM_1YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 2 then 1 else 0 end) as 'JM_2YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 3 then 1 else 0 end) as 'JM_3YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 4 then 1 else 0 end) as 'JM_4YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 5 then 1 else 0 end) as 'JM_5YrBehindSchool', \"\n",
    "\"sum(cast(dis as int)) as 'JM_Sum_of_Disabled', \"\n",
    "\"sum(cast(male as int)) as 'JM_Sum_Of_Males', \"\n",
    "\"sum(cast(female as int)) as 'JM_Sum_Of_Females', \"\n",
    "\"sum(cast(estadocivil1 as int)) as  'JM_estadocivil1', \"\n",
    "\"sum(cast(estadocivil2 as int)) as  'JM_estadocivil2', \"\n",
    "\"sum(cast(estadocivil3 as int)) as  'JM_estadocivil3', \"\n",
    "\"sum(cast(estadocivil4 as int)) as  'JM_estadocivil4', \"\n",
    "\"sum(cast(estadocivil5 as int)) as  'JM_estadocivil5', \"\n",
    "\"sum(cast(estadocivil6 as int)) as  'JM_estadocivil6', \"\n",
    "\"sum(cast(estadocivil7 as int)) as  'JM_estadocivil7', \"\n",
    "\"sum(cast(parentesco1 as int)) as  'JM_parentesco1', \"\n",
    "\"sum(cast(parentesco2 as int)) as  'JM_parentesco2', \"\n",
    "\"sum(cast(parentesco3 as int)) as  'JM_parentesco3', \"\n",
    "\"sum(cast(parentesco4 as int)) as  'JM_parentesco4', \"\n",
    "\"sum(cast(parentesco5 as int)) as  'JM_parentesco5', \"\n",
    "\"sum(cast(parentesco6 as int)) as  'JM_parentesco6', \"\n",
    "\"sum(cast(parentesco7 as int)) as  'JM_parentesco7', \"\n",
    "\"sum(cast(parentesco8 as int)) as  'JM_parentesco8', \"\n",
    "\"sum(cast(parentesco9 as int)) as  'JM_parentesco9', \"\n",
    "\"sum(cast(parentesco10 as int)) as  'JM_parentesco10', \"\n",
    "\"sum(cast(parentesco11 as int)) as  'JM_parentesco11', \"\n",
    "\"sum(cast(parentesco12 as int)) as  'JM_parentesco12', \"\n",
    "\"sum(cast(instlevel1 as int)) as  'JM_instlevel1', \"\n",
    "\"sum(cast(instlevel2 as int)) as  'JM_instlevel2', \"\n",
    "\"sum(cast(instlevel3 as int)) as  'JM_instlevel3', \"\n",
    "\"sum(cast(instlevel4 as int)) as  'JM_instlevel4', \"\n",
    "\"sum(cast(instlevel5 as int)) as  'JM_instlevel5', \"\n",
    "\"sum(cast(instlevel6 as int)) as  'JM_instlevel6', \"\n",
    "\"sum(cast(instlevel7 as int)) as  'JM_instlevel7', \"\n",
    "\"sum(cast(instlevel8 as int)) as  'JM_instlevel8', \"\n",
    "\"sum(cast(instlevel9 as int)) as  'JM_instlevel9', \"\n",
    "\"sum(cast(mobilephone as int)) as  'JM_mobilephone'\" \n",
    "\"from train \"\n",
    "\"group by idhogar \"\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "test_member_agg = pd.DataFrame(sqldf(\"select  \"\n",
    "\"idhogar, \"\n",
    "\"sum(cast(v18q as int)) 'JM_Sum_of_Tablets', \"\n",
    "\"sum(cast(escolari as int)) 'Total Sum Years of Schooling', \"\n",
    "\"sum(case when escolari < 5 then 1 else 0 end) as 'JM_People_Educ_LT5', \"\n",
    "\"sum(case when escolari < 10 then 1 else 0 end) as 'JM_People_Educ_LT10', \"\n",
    "\"sum(case when escolari < 15 then 1 else 0 end) as 'JM_People_Educ_LT15', \"\n",
    "\"sum(case when escolari < 20 then 1 else 0 end) as 'JM_People_Educ_LT20', \"\n",
    "\"sum(case when escolari < 25 then 1 else 0 end) as 'JM_People_Educ_LT25', \"\n",
    "\"sum(case when rez_esc = 1 then 1 else 0 end) as 'JM_1YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 2 then 1 else 0 end) as 'JM_2YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 3 then 1 else 0 end) as 'JM_3YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 4 then 1 else 0 end) as 'JM_4YrBehindSchool', \"\n",
    "\"sum(case when rez_esc = 5 then 1 else 0 end) as 'JM_5YrBehindSchool', \"\n",
    "\"sum(cast(dis as int)) as 'JM_Sum_of_Disabled', \"\n",
    "\"sum(cast(male as int)) as 'JM_Sum_Of_Males', \"\n",
    "\"sum(cast(female as int)) as 'JM_Sum_Of_Females', \"\n",
    "\"sum(cast(estadocivil1 as int)) as  'JM_estadocivil1', \"\n",
    "\"sum(cast(estadocivil2 as int)) as  'JM_estadocivil2', \"\n",
    "\"sum(cast(estadocivil3 as int)) as  'JM_estadocivil3', \"\n",
    "\"sum(cast(estadocivil4 as int)) as  'JM_estadocivil4', \"\n",
    "\"sum(cast(estadocivil5 as int)) as  'JM_estadocivil5', \"\n",
    "\"sum(cast(estadocivil6 as int)) as  'JM_estadocivil6', \"\n",
    "\"sum(cast(estadocivil7 as int)) as  'JM_estadocivil7', \"\n",
    "\"sum(cast(parentesco1 as int)) as  'JM_parentesco1', \"\n",
    "\"sum(cast(parentesco2 as int)) as  'JM_parentesco2', \"\n",
    "\"sum(cast(parentesco3 as int)) as  'JM_parentesco3', \"\n",
    "\"sum(cast(parentesco4 as int)) as  'JM_parentesco4', \"\n",
    "\"sum(cast(parentesco5 as int)) as  'JM_parentesco5', \"\n",
    "\"sum(cast(parentesco6 as int)) as  'JM_parentesco6', \"\n",
    "\"sum(cast(parentesco7 as int)) as  'JM_parentesco7', \"\n",
    "\"sum(cast(parentesco8 as int)) as  'JM_parentesco8', \"\n",
    "\"sum(cast(parentesco9 as int)) as  'JM_parentesco9', \"\n",
    "\"sum(cast(parentesco10 as int)) as  'JM_parentesco10', \"\n",
    "\"sum(cast(parentesco11 as int)) as  'JM_parentesco11', \"\n",
    "\"sum(cast(parentesco12 as int)) as  'JM_parentesco12', \"\n",
    "\"sum(cast(instlevel1 as int)) as  'JM_instlevel1', \"\n",
    "\"sum(cast(instlevel2 as int)) as  'JM_instlevel2', \"\n",
    "\"sum(cast(instlevel3 as int)) as  'JM_instlevel3', \"\n",
    "\"sum(cast(instlevel4 as int)) as  'JM_instlevel4', \"\n",
    "\"sum(cast(instlevel5 as int)) as  'JM_instlevel5', \"\n",
    "\"sum(cast(instlevel6 as int)) as  'JM_instlevel6', \"\n",
    "\"sum(cast(instlevel7 as int)) as  'JM_instlevel7', \"\n",
    "\"sum(cast(instlevel8 as int)) as  'JM_instlevel8', \"\n",
    "\"sum(cast(instlevel9 as int)) as  'JM_instlevel9', \"\n",
    "\"sum(cast(mobilephone as int)) as  'JM_mobilephone'\" \n",
    "\"from test \"\n",
    "\"group by idhogar \"\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "#Join the household and member aggregation together\n",
    "train_model_set = pd.DataFrame(pd.merge(train_head, train_member_agg, on = 'idhogar', how = 'left'))\n",
    "test_model_set = pd.DataFrame(pd.merge(test_head, test_member_agg, on = 'idhogar', how = 'left'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For the rest of the v2a1 that are null, we will use the mean\n",
    "\n",
    "train_model_set['v2a1'].fillna((train_model_set['v2a1'].mean()), inplace=True)\n",
    "\n",
    "test_model_set['v2a1'].fillna((train_model_set['v2a1'].mean()), inplace=True)\n",
    "\n",
    "#Export final model csvs for review\n",
    "train_model_set.to_csv(\"train_model_set.csv\")\n",
    "test_model_set.to_csv(\"test_model_set.csv\")\n",
    "\n",
    "#Make sure all Nulls are accounted for\n",
    "null_columns=train_model_set.columns[train_model_set.isnull().any()]\n",
    "\n",
    "train_model_set[null_columns].isnull().sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parentesco1</th>\n",
       "      <th>hhsize</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>JM_instlevel1</th>\n",
       "      <th>JM_instlevel2</th>\n",
       "      <th>JM_instlevel3</th>\n",
       "      <th>JM_instlevel4</th>\n",
       "      <th>JM_instlevel5</th>\n",
       "      <th>JM_instlevel6</th>\n",
       "      <th>JM_instlevel7</th>\n",
       "      <th>JM_instlevel8</th>\n",
       "      <th>JM_instlevel9</th>\n",
       "      <th>JM_mobilephone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "      <td>2973.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.00</td>\n",
       "      <td>3.21</td>\n",
       "      <td>51596.37</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4.79</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>111678.84</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>51596.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>2353477.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       parentesco1  hhsize       v2a1  hacdor   rooms  hacapo    v14a  refrig  \\\n",
       "count      2973.00 2973.00    2973.00 2973.00 2973.00 2973.00 2973.00 2973.00   \n",
       "mean          1.00    3.21   51596.37    0.02    4.79    0.01    0.99    0.95   \n",
       "std           0.00    1.59  111678.84    0.14    1.45    0.11    0.08    0.21   \n",
       "min           1.00    1.00       0.00    0.00    1.00    0.00    0.00    0.00   \n",
       "25%           1.00    2.00       0.00    0.00    4.00    0.00    1.00    1.00   \n",
       "50%           1.00    3.00       0.00    0.00    5.00    0.00    1.00    1.00   \n",
       "75%           1.00    4.00   51596.37    0.00    6.00    0.00    1.00    1.00   \n",
       "max           1.00   13.00 2353477.00    1.00   11.00    1.00    1.00    1.00   \n",
       "\n",
       "        v18q1    r4h1       ...        JM_instlevel1  JM_instlevel2  \\\n",
       "count 2973.00 2973.00       ...              2973.00        2973.00   \n",
       "mean     0.30    0.26       ...                 0.43           0.54   \n",
       "std      0.66    0.56       ...                 0.72           0.78   \n",
       "min      0.00    0.00       ...                 0.00           0.00   \n",
       "25%      0.00    0.00       ...                 0.00           0.00   \n",
       "50%      0.00    0.00       ...                 0.00           0.00   \n",
       "75%      0.00    0.00       ...                 1.00           1.00   \n",
       "max      6.00    5.00       ...                 5.00           5.00   \n",
       "\n",
       "       JM_instlevel3  JM_instlevel4  JM_instlevel5  JM_instlevel6  \\\n",
       "count        2973.00        2973.00        2973.00        2973.00   \n",
       "mean            0.67           0.60           0.36           0.06   \n",
       "std             0.84           0.83           0.63           0.26   \n",
       "min             0.00           0.00           0.00           0.00   \n",
       "25%             0.00           0.00           0.00           0.00   \n",
       "50%             0.00           0.00           0.00           0.00   \n",
       "75%             1.00           1.00           1.00           0.00   \n",
       "max             7.00           5.00           4.00           3.00   \n",
       "\n",
       "       JM_instlevel7  JM_instlevel8  JM_instlevel9  JM_mobilephone  \n",
       "count        2973.00        2973.00        2973.00         2973.00  \n",
       "mean            0.05           0.45           0.05            3.13  \n",
       "std             0.24           0.75           0.24            1.67  \n",
       "min             0.00           0.00           0.00            0.00  \n",
       "25%             0.00           0.00           0.00            2.00  \n",
       "50%             0.00           0.00           0.00            3.00  \n",
       "75%             0.00           1.00           0.00            4.00  \n",
       "max             3.00           5.00           2.00           13.00  \n",
       "\n",
       "[8 rows x 145 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "train_model_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding 2\n",
    "\n",
    "- [ ] Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 1\n",
    "\n",
    "- [ ] Train and adjust parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 2\n",
    "\n",
    "[ ] Evaluate and Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 3\n",
    "[ ] Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 4\n",
    "\n",
    "\n",
    "[ ] Summarize the Ramifications\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment \n",
    "\n",
    "[ ]Be critical of your performance and tell the reader how you current model might be usable by other parties. Did you achieve your goals? If not, can you reign in the utility of your modeling? How useful is your model for interested parties (i.e., the companies or organizations that might want to use it)? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "\n",
    "You have free reign to provide additional analyses or combine analyses.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
