{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2\n",
    "\n",
    "### Authors: Jason Lin, Jason Lingle, Jonathan Marin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 1\n",
    "\n",
    "- [ ] Define and prepare your class variables.\n",
    "- [ ] Use proper variable representations (int, float, one-hot, etc.)\n",
    "- [ ] Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc.\n",
    "- [ ] Remove variables that are not needed/useful for the analysis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation Part 1 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 2 \n",
    "- [ ] Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation Part 2 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 1\n",
    "\n",
    "- [ ] Choose and explain your evaluation metrics that you will use (i.e., accuracy,precision, recall, F-measure, or any metric we have discussed).\n",
    "\n",
    "- [ ] Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling and Evalutaiton 1 Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 2\n",
    "\n",
    "- [ ] Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling and Evaluation 2 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 3\n",
    "\n",
    "- [ ] Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. \n",
    "- [ ] You must investigate different parameters of the algorithms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling and Evaluation 3 Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 4\n",
    "\n",
    "- [ ] Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. - \n",
    "\n",
    "- [ ] Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling and Evaluation 4 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 5\n",
    "\n",
    "- [ ] Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? \n",
    "\n",
    "- [ ] Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling and Evaludation 6 Code\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 6\n",
    "\n",
    "- [ ] Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. \n",
    "\n",
    "- [ ] Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling and Evaluation 6 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "- [ ] How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? \n",
    "- [ ] How would you measure the model's value if it was used by these parties? \n",
    "- [ ] How would your deploy your model for interested parties? \n",
    "- [ ] What other data should be collected? \n",
    "- [ ] How often would the model need to be updated, etc.? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deployment Code (if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "\n",
    "- [ ] You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exceptional Work Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
